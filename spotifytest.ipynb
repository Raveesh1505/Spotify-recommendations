{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession \n",
    "import pyspark.sql.functions as fun\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/17 13:15:17 WARN Utils: Your hostname, Raveeshs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "23/07/17 13:15:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/17 13:15:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[2]\").appName(\"ML_MODEL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ML_MODEL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13805ba60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "CLIENT_ID = os.getenv(\"CLIENT_ID\")\n",
    "CLIENT_SECRET = os.getenv(\"CLIENT_SECRET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getToken():\n",
    "    authString = f\"{CLIENT_ID}:{CLIENT_SECRET}\"\n",
    "    authBytes = authString.encode(\"utf-8\")\n",
    "    authBase64 = str(base64.b64encode(authBytes), \"utf-8\")\n",
    "\n",
    "    url = \"https://accounts.spotify.com/api/token\"\n",
    "    tokenHeaders = {\n",
    "        \"Authorization\" : f\"Basic {authBase64}\",\n",
    "        \"Content-Type\" : \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    tokenData = {\n",
    "        \"grant_type\" : \"client_credentials\"\n",
    "    }\n",
    "    tokenResponse = requests.post(\n",
    "        url,\n",
    "        headers=tokenHeaders,\n",
    "        data=tokenData\n",
    "    )\n",
    "    tokenData = tokenResponse.json()\n",
    "    TOKEN = tokenData['access_token']\n",
    "    return TOKEN\n",
    "\n",
    "TOKEN = getToken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrack(token, song_name, artist_name):\n",
    "    url = \"https://api.spotify.com/v1/search\"\n",
    "    query = f\"?q=track:{song_name}%20artist:{artist_name}&type=track&limit=1\"\n",
    "    queryURL = url+query\n",
    "    songHeaders = {\n",
    "        \"Authorization\" : f\"Bearer {token}\"\n",
    "    }\n",
    "    songResponse = requests.get(\n",
    "        queryURL,\n",
    "        headers=songHeaders\n",
    "    )\n",
    "    songData = songResponse.json()\n",
    "    songDF = pd.json_normalize(songData['tracks'], record_path='items')\n",
    "    ID = songDF['id'].iloc[0]\n",
    "    return ID\n",
    "\n",
    "songID = getTrack(TOKEN, \"I hate the way\", \"Sofia Carson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3cN3ze6ErUKT3xghdZPQCw\n"
     ]
    }
   ],
   "source": [
    "print(songID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongFeatures(token, songID):\n",
    "    url = f'https://api.spotify.com/v1/audio-features?ids={songID}'\n",
    "    songFeaturesHeaders = {\n",
    "        \"Authorization\" : f\"Bearer {token}\"\n",
    "    }\n",
    "    featureResponse = requests.get(\n",
    "        url,\n",
    "        headers=songFeaturesHeaders\n",
    "    )\n",
    "    data = featureResponse.json()\n",
    "    dataDF = pd.json_normalize(data['audio_features'])\n",
    "    dataDF = dataDF.iloc[:, :11]\n",
    "    dataRaw = spark.createDataFrame(dataDF)\n",
    "    return dataRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = getSongFeatures(TOKEN, songID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "songPredictionModel = LogisticRegressionModel.load('songPredictionModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def songPredict(features, songPredictionModel):\n",
    "    feature_names = features.columns[:]\n",
    "    assembler = VectorAssembler(inputCols=feature_names, outputCol=\"features\")\n",
    "    testingData = assembler.transform(features)\n",
    "    predictionDF = songPredictionModel.transform(testingData)\n",
    "    prediction = predictionDF.first()[\"prediction\"]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = songPredict(features, songPredictionModel)\n",
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
